{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scipy.sparse\n",
    "import tqdm\n",
    "import xswap\n",
    "\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Download raw transcription factor binding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tftg_url = ('https://static-content.springer.com/esm/art%3A10.1186%2Fs12915-017-0469-0/'\n",
    "            'MediaObjects/12915_2017_469_MOESM5_ESM.gmt')\n",
    "tftg_path = '../data/1.raw/tftg.gmt'\n",
    "\n",
    "# with open(tftg_path, 'wb') as f:\n",
    "#     res = requests.get(tftg_url)\n",
    "#     f.write(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Format data into edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 unique transcription factors\n",
      "17155 unique genes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_entrez</th>\n",
       "      <th>tf_name</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>method</th>\n",
       "      <th>test_recon</th>\n",
       "      <th>test_new</th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10009</td>\n",
       "      <td>ZBTB33</td>\n",
       "      <td>CDKN2A</td>\n",
       "      <td>low throughtput</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10009</td>\n",
       "      <td>ZBTB33</td>\n",
       "      <td>MMP7</td>\n",
       "      <td>low throughtput</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tf_entrez tf_name gene_name           method  test_recon  test_new  train\n",
       "0     10009  ZBTB33    CDKN2A  low throughtput           1         0      1\n",
       "1     10009  ZBTB33      MMP7  low throughtput           1         0      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = list()\n",
    "with open(tftg_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        groups = line.strip().split('\\t')\n",
    "        tf_name, tf_entrez = groups[0].split('_')[-2:]\n",
    "        method = re.match('\\A([A-Za-z\\-\\ ]+)(?=(\\ Transcriptional|\\ TFTG))', groups[1]).group().lower()\n",
    "        for gene in groups[2:]:\n",
    "            records.append(\n",
    "                (tf_entrez, tf_name, gene, method)\n",
    "            )\n",
    "\n",
    "np.random.seed(0)\n",
    "edges_df = (\n",
    "    pd.DataFrame\n",
    "    .from_records(records, columns=['tf_entrez', 'tf_name', 'gene_name', 'method'])\n",
    "    .assign(\n",
    "        test_recon=lambda df: (df['method'] == 'low throughtput').astype(int),\n",
    "        test_new=lambda df: (df['method'] == 'chip-seq').astype(int),\n",
    "        train=lambda df: df['test_recon'].apply(lambda x: x == 1 and np.random.rand() < 0.7).astype(int),\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"{} unique transcription factors\\n{} unique genes\".format(len(set(edges_df['tf_name'])), \n",
    "                                                                len(set(edges_df['gene_name']))))\n",
    "\n",
    "edges_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Create train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = sorted(map(tuple, edges_df.query('train == 1').loc[:, 'tf_name':'gene_name'].values))\n",
    "nodes = sorted(set(edge[0] for edge in edges).union(set(edge[1] for edge in edges)))\n",
    "\n",
    "# Since only a small subset of genes are transcription factors in our data,\n",
    "# we need a custom mapping so that we don't have to always deal with a massive matrix\n",
    "\n",
    "tfs = sorted(set(edge[0] for edge in edges))\n",
    "genes_only = sorted(set(edge[1] for edge in edges).difference(set(tfs)))\n",
    "\n",
    "mapping = {tf: i for i, tf in enumerate(tfs)}\n",
    "i = len(tfs)\n",
    "for gene in (genes_only):\n",
    "    mapping[gene] = i\n",
    "    i += 1\n",
    "reversed_mapping = {v: k for k, v in mapping.items()}\n",
    "    \n",
    "source, target = zip(*edges)\n",
    "mapped_edges = list(zip(map(mapping.get, source), map(mapping.get, target)))\n",
    "\n",
    "mat = analysis.edges_to_matrix(mapped_edges, directed=True).tocsc()\n",
    "\n",
    "# Because the graph is directed, we can reduce the size of many computations by only using\n",
    "# relevant and nonzero matrix portions\n",
    "n = len(tfs)\n",
    "degree = np.repeat(mat.sum(axis=1)[:n], n, axis=1) \\\n",
    "         + np.repeat(mat.sum(axis=1)[:n].T, n, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39982727571d488f8f8f87978190eb6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute features on unpermuted network\n",
    "feature_mats = {\n",
    "    'prior_empirical': scipy.sparse.csc_matrix((n, mat.shape[1]), dtype=float),\n",
    "    \n",
    "    'rwr': analysis.rwr_approx_inv(mat, 0.25, 20)[:n],\n",
    "    'mean_rwr': scipy.sparse.csc_matrix((n, mat.shape[1]), dtype=float),\n",
    "    'p_rwr': scipy.sparse.csc_matrix((n, mat.shape[1]), dtype=float),\n",
    "    \n",
    "    # Jaccard only makes sense with respect to TFs as other genes have out-degree zero\n",
    "    'jaccard': analysis.jaccard(mat[:n], degree),\n",
    "    'mean_jaccard': scipy.sparse.csc_matrix((n, n), dtype=float),\n",
    "    'p_jaccard': scipy.sparse.csc_matrix((n, n), dtype=float),\n",
    "}\n",
    "\n",
    "n_perms = 1000\n",
    "\n",
    "perm_edges = mapped_edges.copy()\n",
    "for i in tqdm.tnrange(n_perms):\n",
    "    # Permute edges\n",
    "    perm_edges, _ = xswap.permute_edge_list(perm_edges, allow_antiparallel=True,\n",
    "                                            allow_self_loops=False, multiplier=10, seed=i)\n",
    "    perm_mat = analysis.edges_to_matrix(perm_edges, directed=True).tocsc()\n",
    "    feature_mats['prior_empirical'] += perm_mat[:n]\n",
    "\n",
    "    # Compute RWR on permuted network\n",
    "    perm_rwr = analysis.rwr_approx_inv(perm_mat, 0.25, 20)[:n]\n",
    "    feature_mats['mean_rwr'] += perm_rwr\n",
    "    feature_mats['p_rwr'] += (perm_rwr < feature_mats['rwr'])\n",
    "\n",
    "    # Compute Jaccard similarity on permuted network\n",
    "    perm_jac = analysis.jaccard(perm_mat[:n], degree)\n",
    "    feature_mats['mean_jaccard'] += perm_jac\n",
    "    feature_mats['p_jaccard'] += (perm_jac < feature_mats['jaccard'])\n",
    "    del perm_mat, perm_rwr, perm_jac\n",
    "\n",
    "del degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>mapped_source</th>\n",
       "      <th>mapped_target</th>\n",
       "      <th>out_degree</th>\n",
       "      <th>in_degree</th>\n",
       "      <th>train</th>\n",
       "      <th>test_recon</th>\n",
       "      <th>test_new</th>\n",
       "      <th>prior_empirical</th>\n",
       "      <th>rwr</th>\n",
       "      <th>mean_rwr</th>\n",
       "      <th>p_rwr</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>mean_jaccard</th>\n",
       "      <th>p_jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AHR</td>\n",
       "      <td>AHR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>2.500001e-01</td>\n",
       "      <td>0.049</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHR</td>\n",
       "      <td>AR</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.039234e-10</td>\n",
       "      <td>5.473652e-09</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AHR</td>\n",
       "      <td>ARNT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.089836e-11</td>\n",
       "      <td>4.891516e-06</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AHR</td>\n",
       "      <td>ATF1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.171561e-09</td>\n",
       "      <td>3.766199e-05</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHR</td>\n",
       "      <td>ATF2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.609309e-08</td>\n",
       "      <td>7.505623e-05</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source target  mapped_source  mapped_target  out_degree  in_degree  train  \\\n",
       "0    AHR    AHR              0              0           5          6    0.0   \n",
       "1    AHR     AR              0              1           5          3    0.0   \n",
       "2    AHR   ARNT              0              2           5          5    0.0   \n",
       "3    AHR   ATF1              0              3           5          9    0.0   \n",
       "4    AHR   ATF2              0              4           5         10    0.0   \n",
       "\n",
       "   test_recon  test_new  prior_empirical           rwr      mean_rwr  p_rwr  \\\n",
       "0         0.0       0.0              0.0  2.500000e-01  2.500001e-01  0.049   \n",
       "1         0.0       0.0              0.0  2.039234e-10  5.473652e-09  0.027   \n",
       "2         0.0       0.0              0.0  1.089836e-11  4.891516e-06  0.049   \n",
       "3         0.0       0.0              1.0  3.171561e-09  3.766199e-05  0.029   \n",
       "4         0.0       0.0              2.0  2.609309e-08  7.505623e-05  0.019   \n",
       "\n",
       "    jaccard  mean_jaccard  p_jaccard  \n",
       "0  1.000000      1.000000      1.000  \n",
       "1  0.000000      0.000581      1.000  \n",
       "2  0.064516      0.000533      0.001  \n",
       "3  0.008197      0.000672      0.080  \n",
       "4  0.035714      0.000750      0.021  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for feature, values in feature_mats.items():\n",
    "    \n",
    "    # Transform all features into dense arrays\n",
    "    if scipy.sparse.issparse(values):\n",
    "        values = values.toarray()\n",
    "    else:\n",
    "        values = np.array(values)\n",
    "    \n",
    "    # Jaccard is only for TF-TF comparisons, so the matrices were square. Need to be padded\n",
    "    if feature in ['jaccard', 'p_jaccard', 'mean_jaccard']:\n",
    "        values = np.pad(values, ((0,0), (0, mat.shape[1]-n)), 'constant')\n",
    "\n",
    "    # Normalize features to their correct values\n",
    "    if feature in ['p_rwr', 'p_jaccard']:\n",
    "        values = (n_perms - values) / n_perms\n",
    "    if feature in ['mean_rwr', 'mean_jaccard']:\n",
    "        values /= n_perms\n",
    "    \n",
    "    df[feature] = values.flatten()\n",
    "    \n",
    "\n",
    "df['mapped_source'], df['mapped_target'] = zip(*itertools.product(range(n), range(mat.shape[1])))\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .assign(\n",
    "        source=df['mapped_source'].map(reversed_mapping),\n",
    "        target=df['mapped_target'].map(reversed_mapping),\n",
    "    )\n",
    "    .merge(edges_df, left_on=['source', 'target'], right_on=['tf_name', 'gene_name'], how='left')\n",
    "    .fillna(0)\n",
    "    .assign(\n",
    "        out_degree=lambda df: df['source'].map(df.groupby('source')['train'].sum().to_dict()).astype(int),\n",
    "        in_degree=lambda df: df['target'].map(df.groupby('target')['train'].sum().to_dict()).astype(int),\n",
    "    )\n",
    "    .filter(items=['source', 'target', 'mapped_source', 'mapped_target', 'out_degree', 'in_degree',\n",
    "                  'train', 'test_recon', 'test_new', 'prior_empirical', 'rwr', 'mean_rwr', 'p_rwr',\n",
    "                  'jaccard', 'mean_jaccard', 'p_jaccard',])\n",
    ")\n",
    "\n",
    "df.to_csv('../data/tftf_result.tsv.xz', index=False, sep='\\t', compression='xz')\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xswap-analysis] *",
   "language": "python",
   "name": "conda-env-xswap-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
