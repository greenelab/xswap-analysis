{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import itertools\n",
    "import re\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import scipy.sparse\n",
    "import tqdm\n",
    "import xswap\n",
    "\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Download raw transcription factor binding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tftg_url = ('https://static-content.springer.com/esm/art%3A10.1186%2Fs12915-017-0469-0/'\n",
    "            'MediaObjects/12915_2017_469_MOESM5_ESM.gmt')\n",
    "tftg_path = '../data/transcription_factor_raw.gmt'\n",
    "\n",
    "# with open(tftg_path, 'wb') as f:\n",
    "#     res = requests.get(tftg_url)\n",
    "#     f.write(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Format data into edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 unique transcription factors\n",
      "17155 unique genes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_entrez</th>\n",
       "      <th>tf_name</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10009</td>\n",
       "      <td>ZBTB33</td>\n",
       "      <td>CDKN2A</td>\n",
       "      <td>low throughtput</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10009</td>\n",
       "      <td>ZBTB33</td>\n",
       "      <td>MMP7</td>\n",
       "      <td>low throughtput</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tf_entrez tf_name gene_name           method\n",
       "0     10009  ZBTB33    CDKN2A  low throughtput\n",
       "1     10009  ZBTB33      MMP7  low throughtput"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = list()\n",
    "with open(tftg_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        groups = line.strip().split('\\t')\n",
    "        tf_name, tf_entrez = groups[0].split('_')[-2:]\n",
    "        method = re.match('\\A([A-Za-z\\-\\ ]+)(?=(\\ Transcriptional|\\ TFTG))', groups[1]).group().lower()\n",
    "        for gene in groups[2:]:\n",
    "            records.append(\n",
    "                (tf_entrez, tf_name, gene, method)\n",
    "            )\n",
    "\n",
    "edges_df = pd.DataFrame.from_records(records, columns=['tf_entrez', 'tf_name', 'gene_name', 'method'])\n",
    "\n",
    "print(\"{} unique transcription factors\\n{} unique genes\".format(len(set(edges_df['tf_name'])), \n",
    "                                                                len(set(edges_df['gene_name']))))\n",
    "\n",
    "edges_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Create train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = sorted(map(tuple, edges_df.query('method == \"low throughtput\"').loc[:, 'tf_name':'gene_name'].values))\n",
    "nodes = sorted(set(edge[0] for edge in edges).union(set(edge[1] for edge in edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.from_edgelist(edges, create_using=nx.DiGraph())\n",
    "\n",
    "g_edges = sorted(g.edges)\n",
    "g_nodes = sorted(g.nodes)\n",
    "\n",
    "assert g_nodes == nodes\n",
    "assert g_edges == edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_weakly_connected(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_strongly_connected(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_edges, mapping, _ = xswap.preprocessing.map_str_edges(edges, bipartite=False)\n",
    "reversed_mapping = {v: k for k, v in mapping.items()}\n",
    "mat = analysis.edges_to_matrix(mapped_edges, directed=True)\n",
    "\n",
    "# Create source, target degree matrices\n",
    "degree = np.repeat(mat.sum(axis=1), mat.shape[1], axis=1) \\\n",
    "       + np.repeat(mat.sum(axis=1).T, mat.shape[0], axis=0)\n",
    "\n",
    "# Compute features on unpermuted network\n",
    "feature_mats = {\n",
    "    'prior_empirical': scipy.sparse.csc_matrix(mat.shape, dtype=np.float32),\n",
    "    \n",
    "    'rwr': analysis.rwr_approx_inv(mat, 0.25, 20),\n",
    "    'mean_rwr': scipy.sparse.csc_matrix(mat.shape, dtype=np.float32),\n",
    "    'p_rwr': scipy.sparse.csc_matrix(mat.shape, dtype=np.float16),\n",
    "    \n",
    "    'jaccard': analysis.jaccard(mat, degree),\n",
    "    'mean_jaccard': scipy.sparse.csc_matrix(mat.shape, dtype=np.float32),\n",
    "    'p_jaccard': scipy.sparse.csc_matrix(mat.shape, dtype=np.float16),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158ea4ad91d94fc7917a29fdd2eceb3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_perms = 2\n",
    "\n",
    "perm_edges = mapped_edges.copy()\n",
    "for i in tqdm.tnrange(n_perms):\n",
    "    # Permute edges\n",
    "    perm_edges, _ = xswap.permute_edge_list(perm_edges, allow_antiparallel=True,\n",
    "                                            allow_self_loops=False, multiplier=10, seed=i)\n",
    "    perm_mat = analysis.edges_to_matrix(perm_edges, directed=True)\n",
    "    feature_mats['prior_empirical'] += perm_mat\n",
    "\n",
    "    # Compute RWR on permuted network\n",
    "    perm_rwr = analysis.rwr_approx_inv(perm_mat, 0.25, 20)\n",
    "    feature_mats['mean_rwr'] += perm_rwr\n",
    "    feature_mats['p_rwr'] += (perm_rwr < feature_mats['rwr'])\n",
    "\n",
    "    # Compute Jaccard similarity on permuted network\n",
    "    perm_jac = analysis.jaccard(perm_mat, degree)\n",
    "    feature_mats['mean_jaccard'] += perm_jac\n",
    "    feature_mats['p_jaccard'] += (perm_jac < feature_mats['jaccard'])\n",
    "    del perm_mat, perm_rwr, perm_jac\n",
    "\n",
    "del degree\n",
    "\n",
    "# Normalize and format all features\n",
    "feature_mats['p_rwr'].data = (n_perms - feature_mats['p_rwr'].data) / n_perms\n",
    "feature_mats['p_jaccard'] = (n_perms - feature_mats['p_jaccard']) / n_perms\n",
    "feature_mats['mean_rwr'] /= n_perms\n",
    "feature_mats['mean_jaccard'] /= n_perms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for feature in list(feature_mats.keys()):\n",
    "    values = feature_mats.pop(feature)\n",
    "    if scipy.sparse.issparse(values):\n",
    "        df[feature] = values.toarray().flatten()\n",
    "    else:\n",
    "        df[feature] = np.array(values).flatten()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "with open('../data/tftg_features.tsv', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    \n",
    "    writer.writerows(zip(\n",
    "        features_gen['prior_empirical'],\n",
    "        features_gen['rwr'],\n",
    "        features_gen['mean_rwr'],\n",
    "        features_gen['p_rwr'],\n",
    "        features_gen['jaccard'],\n",
    "        features_gen['mean_jaccard'],\n",
    "        features_gen['p_jaccard'],        \n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xswap-analysis]",
   "language": "python",
   "name": "conda-env-xswap-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
