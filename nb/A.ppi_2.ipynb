{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import tqdm\n",
    "import xswap\n",
    "\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1389 unique genes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_a</th>\n",
       "      <th>uniprot_b</th>\n",
       "      <th>train</th>\n",
       "      <th>string</th>\n",
       "      <th>ht_2014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4D1E9</td>\n",
       "      <td>A4D1E9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A4D1E9</td>\n",
       "      <td>O00144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A4D1E9</td>\n",
       "      <td>O00148</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4D1E9</td>\n",
       "      <td>O00151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A4D1E9</td>\n",
       "      <td>O00160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_a uniprot_b  train  string  ht_2014\n",
       "0    A4D1E9    A4D1E9      0     0.0      0.0\n",
       "1    A4D1E9    O00144      0     0.0      0.0\n",
       "2    A4D1E9    O00148      1     1.0      0.0\n",
       "3    A4D1E9    O00151      0     1.0      0.0\n",
       "4    A4D1E9    O00160      0     0.0      0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('edges_df.tsv.gz')\n",
    "\n",
    "np.random.seed(0)\n",
    "edges_df = (\n",
    "    df\n",
    "    .assign(\n",
    "        train=df['string'].apply(lambda x: x == 1 and np.random.rand() < 0.7).astype(int)\n",
    "    )\n",
    "    .filter(items=['uniprot_a', 'uniprot_b', 'train', 'string', 'ht_2014'])\n",
    ")\n",
    "\n",
    "print(\"{} unique genes\".format(len(set(edges_df.iloc[:, 0:2].values.flatten()))))\n",
    "\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract edge tuples\n",
    "string_edges_df = edges_df.query('train == 1')\n",
    "edges = zip(string_edges_df['uniprot_a'], string_edges_df['uniprot_b'])\n",
    "edges = list(set(map(tuple, map(sorted, edges))))\n",
    "mapped_edges, mapping, _ = (\n",
    "    xswap.preprocessing.map_str_edges(edges, bipartite=False))   \n",
    "\n",
    "# Create adjacency matrix\n",
    "sp_mat = analysis.edges_to_matrix(mapped_edges)\n",
    "\n",
    "# Create source, target degree matrices\n",
    "degree = np.repeat(sp_mat.sum(axis=1), sp_mat.shape[1], axis=1) \\\n",
    "       + np.repeat(sp_mat.sum(axis=0), sp_mat.shape[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3eab79058f24cf4b7d4ed750abaf5b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-79e3338adffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Permute edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     perm_edges, _ = xswap.permute_edge_list(perm_edges, allow_self_loops=True, \n\u001b[0;32m---> 19\u001b[0;31m                                             allow_antiparallel=False, seed=i)\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mperm_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges_to_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfeature_mats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prior_empirical'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mperm_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xswap-analysis/lib/python3.6/site-packages/xswap/xswap.py\u001b[0m in \u001b[0;36mpermute_edge_list\u001b[0;34m(edge_list, allow_self_loops, allow_antiparallel, multiplier, excluded_edges, seed)\u001b[0m\n\u001b[1;32m     46\u001b[0m     new_edges, stats = xswap._xswap_backend._xswap(\n\u001b[1;32m     47\u001b[0m         \u001b[0medge_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcluded_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_self_loops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         allow_antiparallel, num_swaps, seed)\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_edges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compute features on unpermuted network\n",
    "feature_mats = {\n",
    "    'prior_empirical': np.zeros(sp_mat.shape),\n",
    "    \n",
    "    'rwr': analysis.invertible_rwr(sp_mat, 0.25),\n",
    "    'mean_rwr': np.zeros(sp_mat.shape),\n",
    "    'p_rwr': np.zeros(sp_mat.shape),\n",
    "    \n",
    "    'jaccard': (sp_mat@sp_mat) / (degree - sp_mat@sp_mat),\n",
    "    'mean_jaccard': np.zeros(sp_mat.shape),\n",
    "    'p_jaccard': np.zeros(sp_mat.shape),\n",
    "}\n",
    "# Compute RWR p-value\n",
    "n_perms = 1000\n",
    "perm_edges = mapped_edges.copy()\n",
    "for i in tqdm.tnrange(n_perms):\n",
    "    # Permute edges\n",
    "    perm_edges, _ = xswap.permute_edge_list(perm_edges, allow_self_loops=True, \n",
    "                                            allow_antiparallel=False, seed=i)\n",
    "    perm_mat = analysis.edges_to_matrix(perm_edges)\n",
    "    feature_mats['prior_empirical'] += perm_mat\n",
    "    \n",
    "    # Compute RWR on permuted network\n",
    "    perm_rwr = analysis.invertible_rwr(perm_mat.toarray(), 0.25)\n",
    "    feature_mats['mean_rwr'] += perm_rwr\n",
    "    feature_mats['p_rwr'] += (perm_rwr >= feature_mats['rwr'])\n",
    "    \n",
    "    # Compute Jaccard similarity on permuted network\n",
    "    A2 = perm_mat@perm_mat\n",
    "    perm_jac = A2 / (degree - A2)\n",
    "    feature_mats['mean_jaccard'] += perm_jac\n",
    "    feature_mats['p_jaccard'] += (perm_jac >= feature_mats['jaccard'])\n",
    "\n",
    "# Normalize features to number of permutations\n",
    "for feature in ['mean_rwr', 'p_rwr', 'mean_jaccard', 'p_jaccard', 'prior_empirical']:\n",
    "    data = feature_mats[feature] / n_perms\n",
    "    if scipy.sparse.issparse(data):\n",
    "        data = data.toarray().flatten()\n",
    "    else:\n",
    "        data = np.array(data).flatten()\n",
    "    feature_mats[feature] = data\n",
    "    \n",
    "feature_dict = {k: np.array(v).flatten() for k, v in feature_mats.items()}\n",
    "\n",
    "# Unmap RWR and add to DataFrame\n",
    "max_id = max(mapping.values())\n",
    "reversed_map = {v: k for k, v in mapping.items()}\n",
    "feature_dict['mapped_source'], feature_dict['mapped_target'] = zip(*itertools.product(\n",
    "    range(max_id+1), range(max_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unmap RWR and add to DataFrame\n",
    "max_id = max(mapping.values())\n",
    "reversed_map = {v: k for k, v in mapping.items()}\n",
    "mapped_source, mapped_target = zip(*itertools.product(range(max_id+1), range(max_id+1)))\n",
    "mapped_rwr_df = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(feature_dict)\n",
    "    .assign(\n",
    "        uniprot_a=lambda df: df['mapped_source'].map(reversed_map),\n",
    "        uniprot_b=lambda df: df['mapped_target'].map(reversed_map)\n",
    "    )\n",
    "    .filter(items=['uniprot_a', 'uniprot_b', 'prior_empirical', \n",
    "                   'rwr', 'mean_rwr', 'p_rwr', \n",
    "                   'jaccard', 'mean_jaccard', 'p_jaccard'])\n",
    ")\n",
    "# Dictionary of node to degree\n",
    "uniprot_to_degree = collections.Counter(edges_df.groupby('uniprot_a')['train'].sum().to_dict())\n",
    "\n",
    "df = (\n",
    "    edges_df\n",
    "    .merge(mapped_rwr_df, on=['uniprot_a', 'uniprot_b'], how='left')\n",
    "    .fillna(0)\n",
    "    .assign(\n",
    "        source_degree=lambda df: df['uniprot_a'].map(uniprot_to_degree),\n",
    "        target_degree=lambda df: df['uniprot_b'].map(uniprot_to_degree),\n",
    "        mean_degree=lambda df: np.sqrt(df['source_degree'] * df['target_degree']),\n",
    "    )\n",
    "    .filter(['uniprot_a', 'uniprot_b', 'source_degree', 'target_degree', 'mean_degree', 'train', \n",
    "             'string', 'ht_2014', 'prior_empirical', 'rwr', 'mean_rwr', 'p_rwr', 'jaccard', \n",
    "             'mean_jaccard', 'p_jaccard',])\n",
    ")\n",
    "\n",
    "df.to_csv('p_vs_rank.tsv.xz', compression='xz', sep='\\t', index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xswap-analysis] *",
   "language": "python",
   "name": "conda-env-xswap-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
