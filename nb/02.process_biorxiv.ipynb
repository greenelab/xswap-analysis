{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BioRxiv collaboration network\n",
    "\n",
    "DOI: 10.1101/515643\n",
    "\n",
    "Rxivist full database (doi:10.5281/zenodo.2566421) at https://zenodo.org/record/2566421\n",
    "\n",
    "\n",
    "I used the following query to export a copy of the Rxivist BioRxiv scrape.\n",
    "\n",
    "```sqlite\n",
    "SELECT \n",
    "    aa.article, \n",
    "    art.title,\n",
    "    auth.id as author_id, \n",
    "    auth.name as author_name, \n",
    "    auth.institution, \n",
    "    art.doi, \n",
    "    art.collection, \n",
    "    art.posted\n",
    "FROM prod.article_authors aa\n",
    "JOIN prod.authors auth\n",
    "\tON aa.author = auth.id\n",
    "JOIN prod.articles art\n",
    "\tON aa.article = art.id\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>author_name</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2715</td>\n",
       "      <td>Shuxiong Wang</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>5373</td>\n",
       "      <td>Filip Ter</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     article    author_name  year\n",
       "0       2715  Shuxiong Wang  2017\n",
       "422     5373      Filip Ter  2015"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rxivist_df = (\n",
    "    pd.read_csv('../data/1.raw/citations.csv')\n",
    "    .dropna()\n",
    "    .assign(\n",
    "        year=lambda df: df['posted'].apply(lambda x: int(x[:4])),\n",
    "    )\n",
    "    .query('collection == \"bioinformatics\"')\n",
    "    .drop(columns=['title', 'author_id', 'institution', 'doi', 'posted', 'collection'])\n",
    ")\n",
    "\n",
    "rxivist_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "      <th>id_a</th>\n",
       "      <th>id_b</th>\n",
       "      <th>train</th>\n",
       "      <th>test_recon</th>\n",
       "      <th>test_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexander Konovalov</td>\n",
       "      <td>Timo Sachsenberg</td>\n",
       "      <td>117</td>\n",
       "      <td>4167</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Christian Fufezan</td>\n",
       "      <td>Timo Sachsenberg</td>\n",
       "      <td>729</td>\n",
       "      <td>4167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name_a            name_b  id_a  id_b  train  test_recon  \\\n",
       "0  Alexander Konovalov  Timo Sachsenberg   117  4167      1           1   \n",
       "1    Christian Fufezan  Timo Sachsenberg   729  4167      0           1   \n",
       "\n",
       "   test_new  \n",
       "0         1  \n",
       "1         1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cutoff = 2017\n",
    "\n",
    "# Self-join to create author-author relationships from author-article relationships\n",
    "biorxiv_edges_df = (\n",
    "    rxivist_df\n",
    "    .merge(rxivist_df, on=['article', 'year'])\n",
    "    .rename(columns={'author_name_x': 'name_a', 'author_name_y': 'name_b'})\n",
    "    # Remove reversed and self-edges\n",
    "    .query('name_a < name_b')\n",
    "    # Only take the first co-authored paper between two authors\n",
    "    .groupby(['name_a', 'name_b'])[['year', 'article']].min()\n",
    "    .reset_index()\n",
    "    .assign(\n",
    "        test_recon=lambda df: df['year'].apply(lambda x: x <= train_cutoff).astype(int),\n",
    "        test_new=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Assert that no duplicate edges appear whatsoever (causes an issue with XSwap and doesn't make sense)\n",
    "assert biorxiv_edges_df.groupby(['name_a', 'name_b'])['test_new'].sum().max() == 1\n",
    "\n",
    "# Subset to largest connected component\n",
    "name_edges = list(map(tuple, biorxiv_edges_df.query('test_recon == 1')[['name_a', 'name_b']].values))\n",
    "G = nx.from_edgelist(name_edges)\n",
    "Gc = max(nx.connected_component_subgraphs(G), key=len)\n",
    "name_edges = list(map(tuple, map(sorted, Gc.edges)))\n",
    "\n",
    "np.random.seed(0)\n",
    "biorxiv_edges_df = (\n",
    "    pd.DataFrame(name_edges, columns=['name_a', 'name_b'])\n",
    "    .merge(\n",
    "        biorxiv_edges_df, how='left', on=['name_a', 'name_b']\n",
    "    )\n",
    "    .assign(\n",
    "        train=lambda df: df['test_recon'].apply(lambda x: x and np.random.rand() < 0.7).astype(int)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a node mapping\n",
    "authors = sorted(set(biorxiv_edges_df.query('train == 1').loc[:, ['name_a', 'name_b']].values.flatten()))\n",
    "biorxiv_mapping = {name: i for name, i in zip(authors, range(len(authors)))}\n",
    "biorxiv_reversed = {v: k for k, v in biorxiv_mapping.items()}\n",
    "\n",
    "# Apply node mapping and reorder edges so id_a < id_b\n",
    "biorxiv_edges_df = (\n",
    "    biorxiv_edges_df\n",
    "    .assign(\n",
    "        mapped_a=lambda df: df['name_a'].map(biorxiv_mapping),\n",
    "        mapped_b=lambda df: df['name_b'].map(biorxiv_mapping),\n",
    "    )\n",
    "    .dropna()\n",
    "    .assign(\n",
    "        id_a=lambda df: df.apply(lambda row: min(row['mapped_a'], row['mapped_b']), axis=1).astype(int),\n",
    "        id_b=lambda df: df.apply(lambda row: max(row['mapped_a'], row['mapped_b']), axis=1).astype(int),\n",
    "        name_a=lambda df: df['id_a'].map(biorxiv_reversed),\n",
    "        name_b=lambda df: df['id_b'].map(biorxiv_reversed),\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    "    .filter(items=['name_a', 'name_b', 'id_a', 'id_b', 'train', 'test_recon', 'test_new'])\n",
    ")\n",
    "\n",
    "assert biorxiv_edges_df.groupby(['name_a', 'name_b']).size().max() == 1\n",
    "assert biorxiv_edges_df.groupby(['id_a', 'id_b']).size().max() == 1\n",
    "\n",
    "biorxiv_edges_df.to_csv('../data/2.edges/biorxiv.tsv.xz', compression='xz', index=False, sep='\\t')\n",
    "\n",
    "biorxiv_edges_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 35s, sys: 4.44 s, total: 8min 39s\n",
      "Wall time: 8min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "biorxiv_df = analysis.process_edges_to_full_network(biorxiv_edges_df, biorxiv_mapping, allow_loop=False, directed=False)\n",
    "biorxiv_df.to_csv('../data/3.all_nodes/biorxiv.tsv.xz', compression='xz', index=False, sep='\\t')\n",
    "\n",
    "biorxiv_df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xswap-analysis] *",
   "language": "python",
   "name": "conda-env-xswap-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
