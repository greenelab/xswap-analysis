{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import tqdm\n",
    "import xswap\n",
    "\n",
    "import analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_a</th>\n",
       "      <th>uniprot_b</th>\n",
       "      <th>train</th>\n",
       "      <th>string</th>\n",
       "      <th>ht_2014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q96KB5</td>\n",
       "      <td>P61964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O43251</td>\n",
       "      <td>Q9BTD8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9H8Y8</td>\n",
       "      <td>Q14088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q96PP8</td>\n",
       "      <td>P48775</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P08670</td>\n",
       "      <td>Q96QU8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  uniprot_a uniprot_b  train  string  ht_2014\n",
       "0    Q96KB5    P61964    1.0     1.0      0.0\n",
       "1    O43251    Q9BTD8    1.0     1.0      0.0\n",
       "2    Q9H8Y8    Q14088    1.0     1.0      0.0\n",
       "3    Q96PP8    P48775    1.0     1.0      0.0\n",
       "4    P08670    Q96QU8    1.0     1.0      0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('edges_df.tsv.gz')\n",
    "edges_df = (\n",
    "    df\n",
    "    .query('string == 1')\n",
    "    .sample(frac=0.7, random_state=0)\n",
    "    .assign(train=1)\n",
    "    .merge(df, on=['uniprot_a', 'uniprot_b', 'string', 'ht_2014'], how='right')\n",
    "    .fillna(0)\n",
    "    .reset_index(drop=True)\n",
    "    .filter(items=['uniprot_a', 'uniprot_b', 'train', 'string', 'ht_2014'])\n",
    ")\n",
    "\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the fraction dropped is 30%\n",
    "\n",
    "edges_df.query('train == 0 and string == 1').shape[0] / (\n",
    "    edges_df.query('train == 0 and string == 1').shape[0]\n",
    "    + edges_df.query('train == 1 and string == 1').shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract edge tuples\n",
    "string_edges_df = edges_df.query('train == 1')\n",
    "edges = zip(string_edges_df['uniprot_a'], string_edges_df['uniprot_b'])\n",
    "edges = list(set(map(tuple, map(sorted, edges))))\n",
    "mapped_edges, mapping, _ = (\n",
    "    xswap.preprocessing.map_str_edges(edges, bipartite=False))   \n",
    "\n",
    "# Create adjacency matrix\n",
    "sp_mat = analysis.edges_to_matrix(mapped_edges)\n",
    "\n",
    "# Create source, target degree matrices\n",
    "degree = np.repeat(sp_mat.sum(axis=1), sp_mat.shape[1], axis=1) \\\n",
    "       + np.repeat(sp_mat.sum(axis=0), sp_mat.shape[0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29df295ce0e24ca8820e3877502f23bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute features on unpermuted network\n",
    "feature_mats = {\n",
    "    'prior_empirical': np.zeros(sp_mat.shape),\n",
    "    \n",
    "    'rwr': analysis.invertible_rwr(sp_mat, 0.25),\n",
    "    'mean_rwr': np.zeros(sp_mat.shape),\n",
    "    'p_rwr': np.zeros(sp_mat.shape),\n",
    "    \n",
    "    'jaccard': (sp_mat@sp_mat) / (degree - sp_mat@sp_mat),\n",
    "    'mean_jaccard': np.zeros(sp_mat.shape),\n",
    "    'p_jaccard': np.zeros(sp_mat.shape),\n",
    "}\n",
    "# Compute RWR p-value\n",
    "n_perms = 1000\n",
    "perm_edges = mapped_edges.copy()\n",
    "for i in tqdm.tnrange(n_perms):\n",
    "    # Permute edges\n",
    "    perm_edges, _ = xswap.permute_edge_list(perm_edges, allow_self_loops=True, \n",
    "                                            allow_antiparallel=False, seed=i)\n",
    "    perm_mat = analysis.edges_to_matrix(perm_edges)\n",
    "    feature_mats['prior_empirical'] += perm_mat\n",
    "    \n",
    "    # Compute RWR on permuted network\n",
    "    perm_rwr = analysis.invertible_rwr(perm_mat.toarray(), 0.25)\n",
    "    feature_mats['mean_rwr'] += perm_rwr\n",
    "    feature_mats['p_rwr'] += (perm_rwr >= feature_mats['rwr'])\n",
    "    \n",
    "    # Compute Jaccard similarity on permuted network\n",
    "    A2 = perm_mat@perm_mat\n",
    "    perm_jac = A2 / (degree - A2)\n",
    "    feature_mats['mean_jaccard'] += perm_jac\n",
    "    feature_mats['p_jaccard'] += (perm_jac >= feature_mats['jaccard'])\n",
    "\n",
    "# Normalize features to number of permutations\n",
    "for feature in ['mean_rwr', 'p_rwr', 'mean_jaccard', 'p_jaccard', 'prior_empirical']:\n",
    "    data = feature_mats[feature] / n_perms\n",
    "    if scipy.sparse.issparse(data):\n",
    "        data = data.toarray().flatten()\n",
    "    else:\n",
    "        data = np.array(data).flatten()\n",
    "    feature_mats[feature] = data\n",
    "    \n",
    "feature_dict = {k: np.array(v).flatten() for k, v in feature_mats.items()}\n",
    "\n",
    "# Unmap RWR and add to DataFrame\n",
    "max_id = max(mapping.values())\n",
    "reversed_map = {v: k for k, v in mapping.items()}\n",
    "feature_dict['mapped_source'], feature_dict['mapped_target'] = zip(*itertools.product(\n",
    "    range(max_id+1), range(max_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-707ff7965d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m mapped_rwr_df = (\n\u001b[1;32m      6\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     .assign(\n\u001b[1;32m      9\u001b[0m         \u001b[0muniprot_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mapped_source'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xswap-analysis/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'only recognize index or columns for orient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xswap-analysis/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xswap-analysis/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[0;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xswap-analysis/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7354\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7356\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7358\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/xswap-analysis/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   7400\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7402\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays must all be same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "# Unmap RWR and add to DataFrame\n",
    "max_id = max(mapping.values())\n",
    "reversed_map = {v: k for k, v in mapping.items()}\n",
    "mapped_source, mapped_target = zip(*itertools.product(range(max_id+1), range(max_id+1)))\n",
    "mapped_rwr_df = (\n",
    "    pd.DataFrame\n",
    "    .from_dict(feature_dict)\n",
    "    .assign(\n",
    "        uniprot_a=lambda df: df['mapped_source'].map(reversed_map),\n",
    "        uniprot_b=lambda df: df['mapped_target'].map(reversed_map)\n",
    "    )\n",
    "    .filter(items=['uniprot_a', 'uniprot_b', 'prior_empirical', \n",
    "                   'rwr', 'mean_rwr', 'p_rwr', \n",
    "                   'jaccard', 'mean_jaccard', 'p_jaccard'])\n",
    ")\n",
    "# Dictionary of node to degree\n",
    "uniprot_to_degree = collections.Counter(edges_df.groupby('uniprot_a')['train'].sum().to_dict())\n",
    "\n",
    "df = (\n",
    "    edges_df\n",
    "    .merge(mapped_rwr_df, on=['uniprot_a', 'uniprot_b'], how='left')\n",
    "    .fillna(0)\n",
    "    .assign(\n",
    "        source_degree=lambda df: df['uniprot_a'].map(uniprot_to_degree),\n",
    "        target_degree=lambda df: df['uniprot_b'].map(uniprot_to_degree),\n",
    "        mean_degree=lambda df: np.sqrt(df['source_degree'] * df['target_degree']),\n",
    "    )\n",
    "    .filter(['uniprot_a', 'uniprot_b', 'source_degree', 'target_degree', 'mean_degree', 'train', \n",
    "             'string', 'ht_2014', 'prior_empirical', 'rwr', 'mean_rwr', 'p_rwr', 'jaccard', \n",
    "             'mean_jaccard', 'p_jaccard',])\n",
    ")\n",
    "\n",
    "df.to_csv('p_vs_rank.tsv.xz', compression='xz', sep='\\t', index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xswap-analysis] *",
   "language": "python",
   "name": "conda-env-xswap-analysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
